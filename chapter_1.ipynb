{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 1\n",
    "\n",
    "# No.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desserts\n"
     ]
    }
   ],
   "source": [
    "str1 = 'stressed'\n",
    "str2 = ''\n",
    "\n",
    "for c in str1:\n",
    "    str2 = c + str2\n",
    "    \n",
    "print(str2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "タクシ\n"
     ]
    }
   ],
   "source": [
    "str1 = 'パタトクカシー'\n",
    "str2 = ''\n",
    "\n",
    "for i in range(1, len(str1), 2):\n",
    "    str2 += str1[i]\n",
    "print(str2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "パタトクカシーー\n"
     ]
    }
   ],
   "source": [
    "str1 = 'パトカー'\n",
    "str2 = 'タクシー'\n",
    "str3 = ''\n",
    "\n",
    "for _ in range(max(len(str1), len(str2))):\n",
    "    if len(str1) > 0:\n",
    "        str3 += str1[0]\n",
    "        str1 = str1[1:]\n",
    "               \n",
    "    if len(str2) > 0:\n",
    "        str3 += str2[0]\n",
    "        str2 = str2[1:]\n",
    "\n",
    "print(str3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5, 8, 9, 7, 9]\n"
     ]
    }
   ],
   "source": [
    "sentence = 'Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.'\n",
    "punctuation_marks = [',', '.']\n",
    "counts = list()\n",
    "\n",
    "for pm in punctuation_marks:\n",
    "    sentence = sentence.replace(pm, '')\n",
    "\n",
    "for word in sentence.split():\n",
    "    counts.append(len(word))\n",
    "    \n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Hi': 0, 'H': 1, 'Li': 2, 'Be': 3, 'Bo': 4, 'C': 19, 'N': 9, 'O': 7, 'F': 8, 'Na': 10, 'Mi': 11, 'Al': 12, 'Si': 13, 'Pe': 14, 'S': 15, 'Ar': 17, 'Ki': 18}\n"
     ]
    }
   ],
   "source": [
    "sentence = 'Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.'\n",
    "punctuation_marks = [',', '.']\n",
    "idx_list=[1, 5, 6, 7, 8, 9, 15, 16, 19]\n",
    "word_pos_dict = dict()\n",
    "\n",
    "for pm in punctuation_marks:\n",
    "    sentence = sentence.replace(pm, '')\n",
    "    \n",
    "for i, word in enumerate(sentence.split()):\n",
    "    if i in idx_list:\n",
    "        word_pos_dict[word[0]] = i\n",
    "    else:\n",
    "        word_pos_dict[word[0] + word[1]] = i\n",
    "\n",
    "print(word_pos_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['I', 'am'], ['am', 'an'], ['an', 'NLPer']]\n",
      "[['I', ' '], [' ', 'a'], ['a', 'm'], ['m', ' '], [' ', 'a'], ['a', 'n'], ['n', ' '], [' ', 'N'], ['N', 'L'], ['L', 'P'], ['P', 'e'], ['e', 'r']]\n"
     ]
    }
   ],
   "source": [
    "def n_gram(sentence, n, type='word'):\n",
    "    if type == 'word':\n",
    "        words = sentence.split()\n",
    "    elif type == 'character':\n",
    "        words = list(sentence) \n",
    "    else:\n",
    "        raise Exeption \n",
    "        \n",
    "    rets = list()\n",
    "    \n",
    "    for i in range(len(words) - n + 1):\n",
    "        tmp = list()\n",
    "        for j in range(i, i + n):\n",
    "            tmp.append(words[j])\n",
    "        rets.append(tmp)\n",
    "    return rets\n",
    "        \n",
    "sentence = 'I am an NLPer'\n",
    "print(n_gram(sentence, 2))\n",
    "print(n_gram(sentence, 2, 'character'))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# No.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "和集合: [('p', 'a'), ('a', 'r'), ('r', 'a'), ('a', 'p'), ('a', 'd'), ('d', 'i'), ('i', 's'), ('s', 'e'), ('a', 'g'), ('g', 'r'), ('p', 'h')]\n",
      "積集合: [('p', 'a'), ('a', 'r'), ('r', 'a'), ('a', 'p')]\n",
      "差集合: [('a', 'd'), ('d', 'i'), ('i', 's'), ('s', 'e')]\n"
     ]
    }
   ],
   "source": [
    "def bigram2set(bigram):\n",
    "    rets = []\n",
    "    for c1, c2 in bigram:\n",
    "        if not (c1, c2) in rets:\n",
    "            rets.append((c1, c2))\n",
    "    return rets\n",
    "\n",
    "def union(X, Y):\n",
    "    rets = []\n",
    "    for c1, c2 in (X + Y):\n",
    "         if not (c1, c2) in rets:\n",
    "            rets.append((c1, c2))\n",
    "    return rets\n",
    "\n",
    "def intersection(X, Y):\n",
    "    rets = []\n",
    "    for c1, c2 in X:\n",
    "        if (c1,c2) in Y:\n",
    "            rets.append((c1, c2))\n",
    "    return rets\n",
    "\n",
    "def difference(X, Y):\n",
    "    rets = X\n",
    "    for c1, c2 in intersection(X, Y):\n",
    "        rets.remove((c1, c2))\n",
    "    return rets\n",
    "\n",
    "str1 = 'paraparaparadise'\n",
    "str2 = 'paragraph'\n",
    "\n",
    "X = bigram2set(n_gram(str1, 2, 'character'))\n",
    "Y = bigram2set(n_gram(str2, 2, 'character'))\n",
    "\n",
    "print('和集合:', union(X, Y)) \n",
    "print('積集合:', intersection(X, Y))\n",
    "print('差集合:', difference(X, Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# No.07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12時の気温は22.4'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_sentence(X, Y, Z):\n",
    "    return '{0}時の{1}は{2}'.format(X, Y, Z)\n",
    "\n",
    "to_sentence(12, '気温', 22.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No.08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row data :  We are going to use A strategy tomorrow.\n",
      "encrypted data :  Wv ziv tlrmt gl fhv A hgizgvtb glnliild.\n",
      "decrypted data :  We are going to use A strategy tomorrow.\n"
     ]
    }
   ],
   "source": [
    "def cipher(sentence):\n",
    "    rets = ''\n",
    "    for c in sentence:\n",
    "        c_ascii = ord(c)\n",
    "        if ord('a') <= c_ascii and c_ascii <= ord('z'):\n",
    "            rets += chr(219 - c_ascii)\n",
    "        else :\n",
    "            rets += c\n",
    "    return rets\n",
    "\n",
    "row_data = 'We are going to use A strategy tomorrow.'\n",
    "print('row data : ', row_data)\n",
    "encrypted_data = cipher(row_data)\n",
    "print('encrypted data : ', encrypted_data)\n",
    "decrypted_data = cipher(encrypted_data)\n",
    "print('decrypted data : ', decrypted_data)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No.09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I culot belie that I colud atucy udned what I was radeg : the phnel pwoer of the huamn mind .'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def random_swap(sentence):\n",
    "    words = sentence.split()\n",
    "    rets = ''\n",
    "    for word in words:\n",
    "        if len(word) > 4:\n",
    "            rets += word[0]\n",
    "            for i in np.random.permutation(range(1,len(a) - 1)) :\n",
    "                rets += word[i]\n",
    "            rets += word[-1] + ' '\n",
    "        else :\n",
    "            #print(word)\n",
    "            rets += word + ' '\n",
    "        \n",
    "    return rets.rstrip(' ')\n",
    "\n",
    "sentence = 'I couldn\\'t believe that I could actually understand what I was reading : the phenomenal power of the human mind .'\n",
    "random_swap(sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
